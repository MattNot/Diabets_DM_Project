{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA MINING - GRUPPO 2\n",
    "## Diabets dataset\n",
    "The aim of this project is to create a model to predict if\n",
    "a patient will be readmitted or not after a specific encounter.\n",
    "\n",
    "The first thing is to import the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "df = pd.read_csv(\"dataset_diabetes/diabetic_data.csv\", low_memory=False, delimiter=',', na_values='?')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset contains 101766 records with 50 columns. The columns\n",
    "are:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df.columns.to_list())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "let's unify the '> 30' and 'no' class value"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unify_value(x: pd.Series) -> pd.Series:\n",
    "    if x['readmitted'] == '>30':\n",
    "        x['readmitted'] = 'NO'\n",
    "    return x\n",
    "\n",
    "df = df.apply(unify_value, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some columns contains null values, in particular"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isna().apply(lambda x: f'{round((sum(x) / df.shape[0]) * 100, 1)}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's check if the 2.2% of null value in race are correlated with the class\n",
    "label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "amount = df[(df['race'].isnull()) & (df['readmitted'] == '<30')].shape[0]\n",
    "total = df[(df['readmitted'] == '<30')].shape[0]\n",
    "percentage = ( amount / total) * 100\n",
    "percentage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are 188 records with our target class value, so we decide to\n",
    "maintain them as \"not assigned\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(df[df['race'].isnull()].index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Many of the pathologies reported in the dataset (afferent to the diag columns) are part of disease macrogroups (as indicated by documentation). Consequently, we decided to group them. Particular is the category other, which contains ranges of pathologies not very frequent in the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since \"weight\", \"payer_code\", \"medical_specialty\" have a high percentage of null\n",
    "value, we can remove them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(columns=['weight', 'payer_code', 'medical_specialty'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are some ids that are equivalent, so we can unify them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def merge_ids(series: pd.Series) -> pd.Series:\n",
    "    if series['admission_type_id'] == 5 or series['admission_type_id'] == 6:\n",
    "        series['admission_type_id'] = 8\n",
    "    if series['discharge_disposition_id'] == 18 or series['discharge_disposition_id'] == 26:\n",
    "        series['discharge_disposition_id'] = 25\n",
    "    if series['admission_source_id'] == 9 or series['admission_source_id'] == 15 or series['admission_source_id'] == 17 or series['admission_source_id'] == 21:\n",
    "        series['admission_source_id'] = 20\n",
    "    return series\n",
    "\n",
    "df = df.apply(merge_ids, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some informations about the column type and the null values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's fix the types"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for attribute in df.columns:\n",
    "    if df[attribute].dtype == np.object:\n",
    "        df[attribute] = df[attribute].astype('category')\n",
    "\n",
    "df['admission_type_id'] = df['admission_type_id'].astype('category')\n",
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].astype('category')\n",
    "df['admission_source_id'] = df['admission_source_id'].astype('category')\n",
    "\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since there are two columns with only one possible value, we can drop them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(columns=['examide', 'citoglipton'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are not interested in patient number and encounter id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(columns=['encounter_id', 'patient_nbr'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The most frequent value for the categorical attributes are:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "info_columns = df.describe(include='category').T\n",
    "info_columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can calculate the percentage of frequency, so we can decide\n",
    "which columns have a very low or very high variability.\n",
    "\n",
    "The upper bound is set to 99%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "upper_bound = 99\n",
    "lower_bound = 0\n",
    "\n",
    "info_columns['freq'] = info_columns['freq'].apply(lambda x: round((x / df.shape[0]) * 100, 1))\n",
    "for info in info_columns.index:\n",
    "    if info_columns.loc[info]['freq'] > upper_bound or info_columns.loc[info]['freq'] < lower_bound:\n",
    "        df = df.drop(columns=[info])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The distribution for the numeric attribute"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['int64']).hist(figsize=(20,15))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "About categorical attributes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "categorical_attr = df.select_dtypes(include=['category']).columns.to_list()\n",
    "for attribute in categorical_attr:\n",
    "    val = df[attribute].value_counts()\n",
    "    val.plot(kind='bar', figsize=(10,5))\n",
    "    plt.ylabel('count')\n",
    "    plt.xlabel(attribute)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How the numerical feature are correlated with the class labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numericAttribute = df.select_dtypes(include=['int64']).columns.to_list()\n",
    "numericAttribute.append('readmitted')\n",
    "\n",
    "for attribute in numericAttribute:\n",
    "    if attribute != 'readmitted':\n",
    "        sb.kdeplot(x= df[attribute], hue= 'readmitted', data=df[numericAttribute])\n",
    "        plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How the categorical feature are correlated with the class labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "categoricalAttributes = df.select_dtypes(include=['category']).columns.to_list()\n",
    "categoricalAttributes.append('readmitted')\n",
    "\n",
    "for attribute in categoricalAttributes:\n",
    "    if attribute != 'readmitted':\n",
    "        attributeCounts = (df.groupby(['readmitted'])[attribute]\n",
    "                     .value_counts(normalize=True)\n",
    "                     .rename('percentage')\n",
    "                     .mul(100)\n",
    "                     .reset_index()\n",
    "                     .sort_values(attribute))\n",
    "        p = sb.barplot(x=attribute, y=\"percentage\", hue=\"readmitted\", data=attributeCounts)\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check the outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['int64']).plot(kind='box', subplots=True, sharex=False, sharey=False, figsize=(15, 27), layout=(5, 4))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Binarization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cat_attributes = list(df.select_dtypes(include = ['category']).columns)\n",
    "cat_attributes.remove('readmitted')\n",
    "cat_attributes.remove('diag_1')\n",
    "cat_attributes.remove('diag_2')\n",
    "cat_attributes.remove('diag_3')\n",
    "df2 = pd.get_dummies(df, columns = cat_attributes)\n",
    "new_attr_list = list(df2.columns)\n",
    "new_attr_list.remove('diag_1')\n",
    "new_attr_list.remove('diag_2')\n",
    "new_attr_list.remove('diag_3')\n",
    "new_attr_list.remove('readmitted')\n",
    "df2 = df2[new_attr_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(df2[new_attr_list], df['readmitted'], test_size=0.4, random_state=0)\n",
    "x = np.array(df2.values)\n",
    "y = np.array(df['readmitted'].values)\n",
    "# define oversampling strategy\n",
    "\n",
    "seed = 121\n",
    "test_size = .2\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=seed)\n",
    "# define oversampling strategy\n",
    "SMOTE = SMOTE()\n",
    "\n",
    "# fit and apply the transform\n",
    "x_train_SMOTE, y_train_SMOTE = SMOTE.fit_resample(x_train, y_train)\n",
    "\n",
    "models = []\n",
    "models.append(('KneiboarsClassifier', KNeighborsClassifier(3)))\n",
    "models.append(('C45', DecisionTreeClassifier(criterion='entropy')))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier( splitter=\"random\", random_state=1, max_depth=5, max_leaf_nodes=15)))\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier(max_depth=5, n_estimators=10, max_features=24)))\n",
    "#models.append(('MLPClassifier',MLPClassifier(alpha=1, max_iter=1000)))\n",
    "models.append(('AdaBoostClassifier',  AdaBoostClassifier()))\n",
    "models.append(('GaussianNaiveBayes', GaussianNB()))\n",
    "#models.append(('QuadraticDiscriminantAnalysis', QuadraticDiscriminantAnalysis()))\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=seed, shuffle = True)\n",
    "    cv_results = cross_val_score(model, x_train_SMOTE, y_train_SMOTE, cv=kfold, scoring='accuracy')\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Evaluation**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### **Do predictions on test set**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(3)\n",
    "model.fit(x_train_SMOTE, y_train_SMOTE)\n",
    "predictions = model.predict(x_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Accuracy: {accuracy_score(y_test, predictions):.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_confusion_matrix(cf, categories='auto', cbar=True, cmap='Blues', title=None):\n",
    "    group_counts = [f'{value}\\n' for value in cf.flatten()]\n",
    "\n",
    "    box_labels = [f'{v1}'.strip() for v1 in group_counts]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "    sb.heatmap(cf, annot=box_labels, fmt='', cmap=cmap, cbar=cbar, xticklabels=categories, yticklabels=categories)\n",
    "\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "categories = ['No', 'Yes']\n",
    "make_confusion_matrix(confusion_matrix(y_test, predictions), categories=categories, cmap='binary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Classification report')\n",
    "print(classification_report(y_test, predictions))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##### **Compute the Roc Curve for each class**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "one_hot_encoding = np.array(pd.get_dummies(y_test, columns = ['readmitted']))\n",
    "\n",
    "\n",
    "probs = []\n",
    "\n",
    "for  _,model in models:\n",
    "    model.fit(x_train_SMOTE, y_train_SMOTE)\n",
    "    probs.append(model.predict_proba(x_test))\n",
    "    \n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(np.unique(y))):\n",
    "    plt.figure()\n",
    "    m = 0\n",
    "\n",
    "    for name, _ in models:\n",
    "        fpr[i], tpr[i], _ = roc_curve(one_hot_encoding[:, i], probs[m][:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, label=name + f' (area = {roc_auc[i]:.2f}')\n",
    "        m += 1\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Class = ' + str(np.unique(y)[i]))\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.show()  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}